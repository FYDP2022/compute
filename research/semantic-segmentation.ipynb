{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chainercv\n",
    "from chainercv.datasets import VOCSemanticSegmentationDataset\n",
    "from chainer.datasets import TransformDataset\n",
    "from chainercv.evaluations import eval_semantic_segmentation\n",
    "import os.path\n",
    "from os import path\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import random\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device =  torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vslam.semantic import Net\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderSegmentation(data.Dataset):\n",
    "        def __init__(self, split):\n",
    "            super(DataLoaderSegmentation, self).__init__()\n",
    "        \n",
    "            if split not in ['train', 'val', 'test']:\n",
    "                raise ValueError('please pick split from \\'train\\', \\'test\\', or \\'val\\'')\n",
    "            \n",
    "            dir_path = os.getcwd()\n",
    "            self.split = split\n",
    "            self.image_paths = os.path.join(dir_path, 'data', 'tas500v1.1', 'tas500v1.1', split)\n",
    "            if self.split != 'test':\n",
    "                self.label_paths = os.path.join(dir_path, 'data', 'tas500v1.1', 'tas500v1.1', split + '_labels_ids')\n",
    "                self.labels = os.listdir(self.label_paths)\n",
    "            self.files = os.listdir(self.image_paths)\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.files)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            image_name = self.files[idx]\n",
    "            \n",
    "            image = Image.open(os.path.join(self.image_paths, image_name)).convert('RGB')\n",
    "\n",
    "            if self.split != 'test':\n",
    "                label_name = self.labels[idx]\n",
    "                mask  = Image.open(os.path.join(self.label_paths, label_name))\n",
    "                x, y = self.transformData(image, mask)\n",
    "                y = np.where((y != 6) & (y != 7) & (y != 20), 2, y)\n",
    "                y = np.where((y == 6) | (y == 7), 0, y)\n",
    "                y = np.where(y == 20, 1, y)\n",
    "                x, y = torch.from_numpy(x).float(), torch.from_numpy(y).long()\n",
    "                x = torch.permute(x, (2, 0, 1))\n",
    "                return x, y\n",
    "            else:\n",
    "                x, y = self.transformData(image, None)\n",
    "                x = torch.from_numpy(x).float()\n",
    "                x = torch.permute(x, (2, 0, 1))\n",
    "                return x\n",
    "    \n",
    "        def transformData(self, image, mask=None):\n",
    "            # Random crop\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(\n",
    "                image, output_size=(512,512))\n",
    "            image = TF.crop(image, i, j, h, w)\n",
    "            if mask is not None:\n",
    "                mask = TF.crop(mask, i, j, h, w)\n",
    "\n",
    "            # Random horizontal flip\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                if mask is not None:\n",
    "                    mask = TF.hflip(mask)\n",
    "\n",
    "            # Random Vertical Flip\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "                if mask is not None:\n",
    "                    mask = TF.vflip(mask)\n",
    "\n",
    "            image = np.array(image)\n",
    "            if mask is not None:\n",
    "                mask  = np.array(mask)\n",
    "            \n",
    "            image = image[:, :, ::-1].copy()\n",
    "            \n",
    "            return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoaderSegmentation('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image():\n",
    "    trunk_label = 10\n",
    "    bush_label = 4\n",
    "    person_label = 20\n",
    "    animal_label = 21\n",
    "    count = 0\n",
    "    max_count = 3\n",
    "    for i in range(len(train_data)):\n",
    "        tmp_count = np.unique(train_data[i][1], return_counts=True)\n",
    "#         print(tmp_count)\n",
    "        if person_label in tmp_count[0]:\n",
    "#             if tmp_count[1][i] > 100\n",
    "            if count == max_count:\n",
    "                break\n",
    "            else:\n",
    "                img, label = train_data[i]\n",
    "                fig = plt.figure(figsize=(4,3))\n",
    "                ax = fig.add_subplot(1,1,1)\n",
    "                plt.title('Image ' + str(i))\n",
    "                ax.imshow(np.rollaxis(img.numpy().astype(int), 0, 0))\n",
    "                count += 1\n",
    "\n",
    "# find_image()\n",
    "\n",
    "palette = [0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 128, 0, 0, 0, 128, 128, 0, 128, 0, 128, 128,\n",
    "           128, 128, 128, 64, 0, 0, 192, 0, 0, 64, 128, 0, 192, 128, 0, 64, 0, 128, 192, 0, 128,\n",
    "           64, 128, 128, 192, 128, 128, 0, 64, 0, 128, 64, 0, 0, 192, 0, 128, 192, 0, 0, 64, 128]\n",
    "\n",
    "# Some relevant images\n",
    "img_113, seg_img_113 = train_data[113]\n",
    "img_28, seg_img_28 = train_data[28]\n",
    "img_354, seg_img_354 = train_data[354]\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    new_mask = Image.fromarray(mask.numpy().astype(np.uint8)).convert('P')\n",
    "    new_mask.putpalette(palette)\n",
    "                      \n",
    "    return new_mask\n",
    "\n",
    "def add_img_plot(fig, index, img, title, sub_plot_id):\n",
    "    ax = fig.add_subplot(sub_plot_id[0],sub_plot_id[1],sub_plot_id[2])\n",
    "    plt.title(title + str(index))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    \n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# person image\n",
    "add_img_plot(fig, 113, np.rollaxis(img_113.numpy().astype(int), 0, 3), 'Image ', [3,2,1])\n",
    "add_img_plot(fig, 113, colorize_mask(seg_img_113), 'Segmented Image ', [3,2,2])\n",
    "# car image\n",
    "add_img_plot(fig, 28, np.rollaxis(img_28.numpy().astype(int), 0, 3), 'Image ', [3,2,3])\n",
    "add_img_plot(fig, 28, colorize_mask(seg_img_28), 'Segmented Image ', [3,2,4])\n",
    "# animal image\n",
    "add_img_plot(fig, 354, np.rollaxis(img_354.numpy().astype(int), 0, 3), 'Image ', [3,2,5])\n",
    "add_img_plot(fig, 354, colorize_mask(seg_img_354), 'Segmented Image ', [3,2,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cpu':\n",
    "    train_loader = DataLoader(train_data, batch_size=5, shuffle=True, num_workers=0)\n",
    "else:\n",
    "    train_loader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "from vslam.semantic import Net\n",
    "untrained_net = Net().to(device)\n",
    "untrained_net.eval()\n",
    "\n",
    "sample_img, sample_target = train_data[113]\n",
    "\n",
    "untrained_output = untrained_net.forward(sample_img[None].to(device))\n",
    "if device != 'cpu':\n",
    "    untrained_output = untrained_output.cpu()\n",
    "untrained_nn_seg_img_113 = torch.argmax(untrained_output.cpu(), dim=1).numpy()[0]\n",
    "\n",
    "fig = plt.figure(figsize=(8,2))\n",
    "add_img_plot(fig, 113, transforms.ToPILImage()(img_113), 'Image ', [1,3,1])\n",
    "add_img_plot(fig, 113, colorize_mask(seg_img_113), 'GT Segmented Image ', [1,3,2])\n",
    "add_img_plot(fig, 113, colorize_mask_nn_output(untrained_nn_seg_img_113), 'NN Segmented Image', [1,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.backends.cudnn as cudnn\n",
    "\n",
    "checkpoint = None\n",
    "batch_size = 3\n",
    "iterations = 170\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.5\n",
    "\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "def adjust_learning_rate(optimizer, lr_to):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = g['lr']*lr_to\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler):\n",
    "    \"\"\"\n",
    "    Save model checkpoint.\n",
    "\n",
    "    :param epoch: epoch number\n",
    "    :param model: model\n",
    "    :param optimizer: optimizer\n",
    "    :param base_type: The base network type\n",
    "    \"\"\"\n",
    "    state = {'epoch': epoch,\n",
    "             'model': model,\n",
    "             'optimizer': optimizer,\n",
    "             'scheduler': scheduler}\n",
    "    if scheduler == None:\n",
    "        filename = 'checkpoint_test_jack.pth.tar'\n",
    "    else:\n",
    "        filename = 'checkpoint_mobilenet_v2_scheduler.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def train_mobilenet_v2(lr_type):\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    global start_epoch, label_map, epoch, checkpoint, delay_lr_at\n",
    "    \n",
    "    train_dataset = DataLoaderSegmentation('train')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    if lr_type == 'original_scheduler':\n",
    "        lr = 1e-1\n",
    "        decay_lr_at = [45000, 55000] # decay learning rate after this many iterations\n",
    "        decay_lr_to = 0.1\n",
    "    elif lr_type == 'pytorch_scheduler':\n",
    "        lr = 1e-3\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    epochs = iterations // (len(train_dataset) // batch_size)\n",
    "    \n",
    "    if lr_type == 'original_scheduler':\n",
    "        decay_lr_at = [it // (len(train_dataset) // batch_size) for it in decay_lr_at]\n",
    "        print(\"Epochs to decay learning rate:\", decay_lr_at)\n",
    "    \n",
    "    if checkpoint is None:\n",
    "        start_epoch = 0\n",
    "        model = Net().to(device)\n",
    "        \n",
    "        optimizer = torch.optim.SGD(model.parameters(),\n",
    "                               lr=lr,\n",
    "                               weight_decay=weight_decay,\n",
    "                               momentum=momentum,\n",
    "                               nesterov=False)\n",
    "        if lr_type == 'pytorch_scheduler':\n",
    "            raise NotImplementedError\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
    "        model = checkpoint['model']\n",
    "        optimizer = checkpoint['optimizer']\n",
    "        if lr_type == 'pytorch_scheduler':\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    model.criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    \n",
    "    loss_graph = []\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.subplots_adjust(bottom=0.2,right=0.85,top=0.95)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \n",
    "        if lr_type == 'original_scheduler':\n",
    "            if epoch in decay_lr_at:\n",
    "                adjust_learning_rate(optimizer, decay_lr_to)\n",
    "                for g in optimizer.param_groups:\n",
    "                    print(\"Optimizer learning rate changed to {}\".format(g['lr']))\n",
    "\n",
    "        loss = train_model(train_loader=train_loader, model=model,loss_graph=loss_graph, epoch=epoch, device=device, optimizer=optimizer)\n",
    "        if lr_type == 'pytorch_scheduler':\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if lr_type == 'original_scheduler':\n",
    "            save_checkpoint(epoch, model, optimizer, scheduler=None)\n",
    "        else:\n",
    "            save_checkpoint(epoch, model, optimizer, scheduler)\n",
    "            \n",
    "        ax.clear()\n",
    "        ax.set_xlabel('iterations')\n",
    "        ax.set_ylabel('loss value')\n",
    "        ax.set_title('Training loss curve for trained  net')\n",
    "        ax.plot(loss_graph, label='training loss')\n",
    "        ax.legend(loc='upper right')\n",
    "        fig.canvas.draw()\n",
    "        print(\"Epoch: {} Loss: {}\".format(epoch, loss))\n",
    "\n",
    "def train_model(train_loader, model, optimizer, epoch, device, loss_graph):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        img, gt_seg_img = data.to(device), target.to(device)\n",
    "        \n",
    "        main_loss = model(img, gts=gt_seg_img)\n",
    "        \n",
    "        loss_graph.append(main_loss.item())\n",
    "        \n",
    "        print(main_loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        main_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return main_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_mobilenet_v2('original_scheduler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = DataLoaderSegmentation('val')\n",
    "val_loader = DataLoader(val_data, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "checkpoint = torch.load('./checkpoint_mobilenet_v2.pth.tar')\n",
    "model = checkpoint['model']\n",
    "model = model.to(device)\n",
    "\n",
    "train_dataset = DataLoaderSegmentation('train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True, num_workers=0)\n",
    "\n",
    "print(\"mIoU over the validation dataset:{}\".format(validate(val_loader, model)[1]))\n",
    "print(\"mIoU over the training dataset:{}\".format(validate(train_loader, model)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask_nn_output(mask):\n",
    "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
    "    new_mask.putpalette(palette)\n",
    "                      \n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, net):\n",
    "    iou_arr = []\n",
    "    val_loss = 0\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            img, gt_seg_img = data.to(device), target.to(device)\n",
    "            \n",
    "            output = net(img)\n",
    "            \n",
    "            if device != 'cpu':\n",
    "                output = output.cpu()\n",
    "                gt_seg_img = gt_seg_img.cpu()\n",
    "            pred = torch.argmax(output, dim=1).numpy()[0]\n",
    "            \n",
    "            gt_np = gt_seg_img.numpy()[0]\n",
    "            \n",
    "            conf = eval_semantic_segmentation(pred[None], gt_np[None])\n",
    "            \n",
    "            iou_arr.append(conf['miou'])\n",
    "            \n",
    "    return val_loss, (sum(iou_arr) / len(iou_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    new_mask = Image.fromarray(mask.numpy().astype(np.uint8)).convert('P')\n",
    "    new_mask.putpalette(palette)\n",
    "                      \n",
    "    return new_mask\n",
    "\n",
    "def add_img_plot(fig, index, img, title, sub_plot_id):\n",
    "    ax = fig.add_subplot(sub_plot_id[0],sub_plot_id[1],sub_plot_id[2])\n",
    "    plt.title(title + str(index))\n",
    "    ax.imshow(img)\n",
    "\n",
    "\n",
    "def add_img_txt_plot(fig, index, img, title, sub_plot_id, txt):\n",
    "    ax = fig.add_subplot(sub_plot_id[0],sub_plot_id[1],sub_plot_id[2])\n",
    "    plt.title(title + str(index))\n",
    "    ax.text(10, 25, 'mIoU = {:_>8.6f}'.format(txt), fontsize=20, color='white')\n",
    "    ax.imshow(img)\n",
    "    \n",
    "def get_nn_seg_img(net, img, mask):\n",
    "    img, get_seg_img = img, mask\n",
    "    \n",
    "    nn_seg_output = net.forward(img[None].cuda())\n",
    "    \n",
    "    if device != 'cpu':\n",
    "        nn_seg_img = torch.argmax(nn_seg_output, dim=1).cpu().numpy()[0]\n",
    "    else:\n",
    "        nn_seg_img = torch.argmax(nn_seg_output, dim=1).numpy()[0]\n",
    "        \n",
    "    gts = get_seg_img.cpu().numpy()\n",
    "    \n",
    "    conf = eval_semantic_segmentation(nn_seg_img[None], gts[None])\n",
    "    \n",
    "#     print(\"View count of pixels within each label category:\")\n",
    "#     print(np.unique(get_seg_img, return_counts=True))\n",
    "#     print(np.unique(nn_seg_img, return_counts=True))\n",
    "    \n",
    "    return nn_seg_img, conf['miou']\n",
    "\n",
    "\n",
    "img_113, seg_img_113 = val_data[25]\n",
    "img_28, seg_img_28 = train_data[99]\n",
    "img_354, seg_img_354 = train_data[100]\n",
    "\n",
    "nn_seg_img_113, miou_113 = get_nn_seg_img(model, img_113, seg_img_113)\n",
    "nn_seg_img_28, miou_28 = get_nn_seg_img(model, img_28, seg_img_28)\n",
    "nn_seg_img_354, miou_354 = get_nn_seg_img(model, img_354, seg_img_354)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "add_img_plot(fig, 113, np.rollaxis(img_113.numpy().astype(int), 0, 3), 'Image ', [3,3,1])\n",
    "add_img_plot(fig, 113, colorize_mask(seg_img_113), 'GT Segmented Image ', [3,3,2])\n",
    "add_img_txt_plot(fig, 113, colorize_mask_nn_output(nn_seg_img_113), 'NN Segmented Image ', [3,3,3], miou_113)\n",
    "add_img_plot(fig, 28, np.rollaxis(img_28.numpy().astype(int), 0, 3), 'Image ', [3,3,4])\n",
    "add_img_plot(fig, 28, colorize_mask(seg_img_28), 'Segmented Image ', [3,3,5])\n",
    "add_img_txt_plot(fig, 28, colorize_mask_nn_output(nn_seg_img_28), 'NN Segmented Image ', [3,3,6], miou_28)\n",
    "add_img_plot(fig, 354, np.rollaxis(img_354.numpy().astype(int), 0, 3), 'Image ', [3,3,7])\n",
    "add_img_plot(fig, 354, colorize_mask(seg_img_354), 'Segmented Image ', [3,3,8])\n",
    "add_img_txt_plot(fig, 354, colorize_mask_nn_output(nn_seg_img_354), 'NN Segmented Image ', [3,3,9], miou_354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DataLoaderSegmentation('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_seg_img_test(net, data):\n",
    "    img = data\n",
    "\n",
    "    nn_seg_output = net.forward(img[None].cuda())\n",
    "\n",
    "    if device != 'cpu':\n",
    "        nn_seg_img = torch.argmax(nn_seg_output, dim=1).cpu().numpy()[0]\n",
    "    else:\n",
    "        nn_seg_img = torch.argmax(nn_seg_output, dim=1).numpy()[0]\n",
    "\n",
    "#     print(\"View count of pixels within each label category:\")\n",
    "#     print(np.unique(nn_seg_img, return_counts=True))\n",
    "\n",
    "    return nn_seg_img\n",
    "\n",
    "test_img_9 = test_data[25]\n",
    "\n",
    "test_nn_seg_img_9 = get_nn_seg_img_test(model, test_data[25])\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "add_img_plot(fig, 9, np.rollaxis(test_img_9.numpy().astype(int), 0, 3),'Test Image ', [3,3,1])\n",
    "add_img_plot(fig, 9, colorize_mask_nn_output(test_nn_seg_img_9), 'Test NN Segmented Image ', [3,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
